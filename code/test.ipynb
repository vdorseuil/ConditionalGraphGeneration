{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import scipy as sp\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import shutil\n",
    "import csv\n",
    "import ast\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from autoencoder import VariationalAutoEncoder\n",
    "from denoise_model import DenoiseNN, p_losses, sample\n",
    "from utils_ipynb import linear_beta_schedule, construct_nx_from_adj, preprocess_dataset\n",
    "\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "np.random.seed(13)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(lr=0.001, dropout=0.0, batch_size=256, epochs_autoencoder=200, hidden_dim_encoder=64, hidden_dim_decoder=256, latent_dim=32, n_max_nodes=50, n_layers_encoder=2, n_layers_decoder=3, spectral_emb_dim=10, epochs_denoise=100, timesteps=500, hidden_dim_denoise=512, n_layers_denoise=3, train_autoencoder=False, train_denoiser=False, dim_condition=128, n_condition=7)\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    'main.py',\n",
    "    '--lr', '0.001',\n",
    "    '--dropout', '0.0',\n",
    "    '--batch-size', '256',\n",
    "    '--epochs-autoencoder', '200',\n",
    "    '--hidden-dim-encoder', '64',\n",
    "    '--hidden-dim-decoder', '256',\n",
    "    '--latent-dim', '32',\n",
    "    '--n-max-nodes', '50',\n",
    "    '--n-layers-encoder', '2',\n",
    "    '--n-layers-decoder', '3',\n",
    "    '--spectral-emb-dim', '10',\n",
    "    '--epochs-denoise', '100',\n",
    "    '--timesteps', '500',\n",
    "    '--hidden-dim-denoise', '512',\n",
    "    '--n-layers_denoise', '3',\n",
    "    # '--train-autoencoder',\n",
    "    # '--train-denoiser',\n",
    "    '--dim-condition', '128',\n",
    "    '--n-condition', '7'\n",
    "]\n",
    "\n",
    "# Initialize the parser\n",
    "parser = argparse.ArgumentParser(description=\"Your description here\")\n",
    "\n",
    "# Add arguments\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help=\"Learning rate for the optimizer, typically a small float value (default: 0.001)\")\n",
    "parser.add_argument('--dropout', type=float, default=0.0, help=\"Dropout rate (fraction of nodes to drop) to prevent overfitting (default: 0.0)\")\n",
    "parser.add_argument('--batch-size', type=int, default=256, help=\"Batch size for training, controlling the number of samples per gradient update (default: 256)\")\n",
    "parser.add_argument('--epochs-autoencoder', type=int, default=200, help=\"Number of training epochs for the autoencoder (default: 200)\")\n",
    "parser.add_argument('--hidden-dim-encoder', type=int, default=64, help=\"Hidden dimension size for encoder layers (default: 64)\")\n",
    "parser.add_argument('--hidden-dim-decoder', type=int, default=256, help=\"Hidden dimension size for decoder layers (default: 256)\")\n",
    "parser.add_argument('--latent-dim', type=int, default=32, help=\"Dimensionality of the latent space in the autoencoder (default: 32)\")\n",
    "parser.add_argument('--n-max-nodes', type=int, default=50, help=\"Possible maximum number of nodes in graphs (default: 50)\")\n",
    "parser.add_argument('--n-layers-encoder', type=int, default=2, help=\"Number of layers in the encoder network (default: 2)\")\n",
    "parser.add_argument('--n-layers-decoder', type=int, default=3, help=\"Number of layers in the decoder network (default: 3)\")\n",
    "parser.add_argument('--spectral-emb-dim', type=int, default=10, help=\"Dimensionality of spectral embeddings for representing graph structures (default: 10)\")\n",
    "parser.add_argument('--epochs-denoise', type=int, default=100, help=\"Number of training epochs for the denoising model (default: 100)\")\n",
    "parser.add_argument('--timesteps', type=int, default=500, help=\"Number of timesteps for the diffusion (default: 500)\")\n",
    "parser.add_argument('--hidden-dim-denoise', type=int, default=512, help=\"Hidden dimension size for denoising model layers (default: 512)\")\n",
    "parser.add_argument('--n-layers_denoise', type=int, default=3, help=\"Number of layers in the denoising model (default: 3)\")\n",
    "parser.add_argument('--train-autoencoder', action='store_true', default=False, help=\"Flag to enable/disable autoencoder (VGAE) training (default: enabled)\")\n",
    "parser.add_argument('--train-denoiser', action='store_true', default=False, help=\"Flag to enable/disable denoiser training (default: enabled)\")\n",
    "parser.add_argument('--dim-condition', type=int, default=128, help=\"Dimensionality of conditioning vectors for conditional generation (default: 128)\")\n",
    "parser.add_argument('--n-condition', type=int, default=7, help=\"Number of distinct condition properties used in conditional vector (default: 7)\")\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Use the arguments as needed\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ../data/dataset_train.pt loaded from file\n",
      "Dataset ../data/dataset_valid.pt loaded from file\n",
      "Dataset ../data/dataset_test.pt loaded from file\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# preprocess train data, validation data and test data. Only once for the first time that you run the code. Then the appropriate .pt files will be saved and loaded.\n",
    "trainset = preprocess_dataset(\"train\", args.n_max_nodes, args.spectral_emb_dim)\n",
    "validset = preprocess_dataset(\"valid\", args.n_max_nodes, args.spectral_emb_dim)\n",
    "testset = preprocess_dataset(\"test\", args.n_max_nodes, args.spectral_emb_dim)\n",
    "\n",
    "# initialize data loaders\n",
    "train_loader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(validset, batch_size=args.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(testset, batch_size=args.batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725842\n"
     ]
    }
   ],
   "source": [
    "# initialize VGAE model\n",
    "autoencoder = VariationalAutoEncoder(args.spectral_emb_dim+1, args.hidden_dim_encoder, args.hidden_dim_decoder, args.latent_dim, args.n_layers_encoder, args.n_layers_decoder, args.n_max_nodes).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "total_params_vae = sum(p.numel() for p in autoencoder.parameters())\n",
    "print(total_params_vae)\n",
    "\n",
    "# if args.train_autoencoder:\n",
    "#     best_val_loss = np.inf\n",
    "#     for epoch in range(1, args.epochs_autoencoder+1):\n",
    "#         autoencoder.train()\n",
    "#         train_loss_all = 0\n",
    "#         train_count = 0\n",
    "#         train_loss_all_recon = 0\n",
    "#         train_loss_all_kld = 0\n",
    "#         cnt_train=0\n",
    "\n",
    "#         for data in train_loader:\n",
    "#             data = data.to(device)\n",
    "#             optimizer.zero_grad()\n",
    "#             loss, recon, kld  = autoencoder.loss_function(data)\n",
    "#             train_loss_all_recon += recon.item()\n",
    "#             train_loss_all_kld += kld.item()\n",
    "#             cnt_train+=1\n",
    "#             loss.backward()\n",
    "#             train_loss_all += loss.item()\n",
    "#             train_count += torch.max(data.batch)+1\n",
    "#             optimizer.step()\n",
    "\n",
    "#         autoencoder.eval()\n",
    "#         val_loss_all = 0\n",
    "#         val_count = 0\n",
    "#         cnt_val = 0\n",
    "#         val_loss_all_recon = 0\n",
    "#         val_loss_all_kld = 0\n",
    "\n",
    "#         for data in val_loader:\n",
    "#             data = data.to(device)\n",
    "#             loss, recon, kld  = autoencoder.loss_function(data)\n",
    "#             val_loss_all_recon += recon.item()\n",
    "#             val_loss_all_kld += kld.item()\n",
    "#             val_loss_all += loss.item()\n",
    "#             cnt_val+=1\n",
    "#             val_count += torch.max(data.batch)+1\n",
    "\n",
    "#         if epoch % 1 == 0:\n",
    "#             dt_t = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "#             print('{} Epoch: {:04d}, Train Loss: {:.5f}, Train Reconstruction Loss: {:.2f}, Train KLD Loss: {:.2f}, Val Loss: {:.5f}, Val Reconstruction Loss: {:.2f}, Val KLD Loss: {:.2f}'.format(dt_t,epoch, train_loss_all/cnt_train, train_loss_all_recon/cnt_train, train_loss_all_kld/cnt_train, val_loss_all/cnt_val, val_loss_all_recon/cnt_val, val_loss_all_kld/cnt_val))\n",
    "            \n",
    "#         scheduler.step()\n",
    "\n",
    "#         if best_val_loss >= val_loss_all:\n",
    "#             best_val_loss = val_loss_all\n",
    "#             torch.save({\n",
    "#                 'state_dict': autoencoder.state_dict(),\n",
    "#                 'optimizer' : optimizer.state_dict(),\n",
    "#             }, './models/autoencoder.pth.tar')\n",
    "# else:\n",
    "#     checkpoint = torch.load('../models/autoencoder.pth.tar')\n",
    "#     autoencoder.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# autoencoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1111060/3359316281.py:67: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('../models/denoise_model.pth.tar')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenoiseNN(\n",
       "  (cond_mlp): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (time_mlp): Sequential(\n",
       "    (0): SinusoidalPositionEmbeddings()\n",
       "    (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (2): GELU(approximate='none')\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (mlp): ModuleList(\n",
       "    (0): Linear(in_features=160, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=640, out_features=512, bias=True)\n",
       "    (2): Linear(in_features=512, out_features=32, bias=True)\n",
       "  )\n",
       "  (bn): ModuleList(\n",
       "    (0-1): 2 x BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define beta schedule\n",
    "betas = linear_beta_schedule(timesteps=args.timesteps)\n",
    "\n",
    "# define alphas\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
    "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
    "\n",
    "# calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "# initialize denoising model\n",
    "denoise_model = DenoiseNN(input_dim=args.latent_dim, hidden_dim=args.hidden_dim_denoise, n_layers=args.n_layers_denoise, n_cond=args.n_condition, d_cond=args.dim_condition).to(device)\n",
    "optimizer = torch.optim.Adam(denoise_model.parameters(), lr=args.lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=500, gamma=0.1)\n",
    "\n",
    "total_params_denoiser = sum(p.numel() for p in denoise_model.parameters())\n",
    "print(total_params_denoiser)\n",
    "\n",
    "# Train denoising model\n",
    "if args.train_denoiser:\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in range(1, args.epochs_denoise+1):\n",
    "        denoise_model.train()\n",
    "        train_loss_all = 0\n",
    "        train_count = 0\n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            x_g = autoencoder.encode(data)\n",
    "            t = torch.randint(0, args.timesteps, (x_g.size(0),), device=device).long()\n",
    "            loss = p_losses(denoise_model, x_g, t, data.stats, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, loss_type=\"huber\")\n",
    "            loss.backward()\n",
    "            train_loss_all += x_g.size(0) * loss.item()\n",
    "            train_count += x_g.size(0)\n",
    "            optimizer.step()\n",
    "\n",
    "        denoise_model.eval()\n",
    "        val_loss_all = 0\n",
    "        val_count = 0\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            x_g = autoencoder.encode(data)\n",
    "            t = torch.randint(0, args.timesteps, (x_g.size(0),), device=device).long()\n",
    "            loss = p_losses(denoise_model, x_g, t, data.stats, sqrt_alphas_cumprod, sqrt_one_minus_alphas_cumprod, loss_type=\"huber\")\n",
    "            val_loss_all += x_g.size(0) * loss.item()\n",
    "            val_count += x_g.size(0)\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            dt_t = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "            print('{} Epoch: {:04d}, Train Loss: {:.5f}, Val Loss: {:.5f}'.format(dt_t, epoch, train_loss_all/train_count, val_loss_all/val_count))\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if best_val_loss >= val_loss_all:\n",
    "            best_val_loss = val_loss_all\n",
    "            torch.save({\n",
    "                'state_dict': denoise_model.state_dict(),\n",
    "                'optimizer' : optimizer.state_dict(),\n",
    "            }, './models/denoise_model.pth.tar')\n",
    "else:\n",
    "    checkpoint = torch.load('../models/denoise_model.pth.tar')\n",
    "    denoise_model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "denoise_model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import community as community_louvain\n",
    "\n",
    "def graph_statistics(G):\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    num_edges = G.number_of_edges()\n",
    "    average_degree = sum(dict(G.degree()).values()) / num_nodes\n",
    "    num_triangles = sum(nx.triangles(G).values()) // 3\n",
    "    global_clustering_coefficient = nx.transitivity(G)\n",
    "    k_core = nx.k_core(G)\n",
    "    max_k_core = max(k_core.nodes())\n",
    "    partition = community_louvain.best_partition(G)\n",
    "    num_communities = len(set(partition.values()))\n",
    "\n",
    "    # Return the results in a list\n",
    "    return [\n",
    "        num_nodes,\n",
    "        num_edges,\n",
    "        average_degree,\n",
    "        num_triangles,\n",
    "        global_clustering_coefficient,\n",
    "        max_k_core,\n",
    "        num_communities\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test set:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test set: 100%|██████████| 4/4 [00:08<00:00,  2.03s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae = 0.\n",
    "for k, data in enumerate(tqdm(test_loader, desc='Processing test set',)):\n",
    "    data = data.to(device)\n",
    "    \n",
    "    stat = data.stats\n",
    "    bs = stat.size(0)\n",
    "\n",
    "    graph_ids = data.filename\n",
    "\n",
    "    samples = sample(denoise_model, data.stats, latent_dim=args.latent_dim, timesteps=args.timesteps, betas=betas, batch_size=bs)\n",
    "    x_sample = samples[-1]\n",
    "    adj = autoencoder.decode_mu(x_sample)\n",
    "    stat_d = torch.reshape(stat, (-1, args.n_condition))\n",
    "    for i in range(stat.size(0)):\n",
    "            stat_x = stat_d[i]\n",
    "\n",
    "            Gs_generated = construct_nx_from_adj(adj[i,:,:].detach().cpu().numpy())\n",
    "            stat_x = stat_x.detach().cpu().numpy()\n",
    "\n",
    "            # Define a graph ID\n",
    "            graph_id = graph_ids[i]\n",
    "            generated_stats  = np.array(graph_statistics(Gs_generated))\n",
    "            mae += mean_absolute_error(stat_x, generated_stats)\n",
    "            \n",
    "only_denoiser_mae = mae/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218.571618988481 391.8316257272973 226.2865684298689 407.82133017459466\n"
     ]
    }
   ],
   "source": [
    "print(train_init_mae, no_train_mae, only_vae_mae, only_denoiser_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
