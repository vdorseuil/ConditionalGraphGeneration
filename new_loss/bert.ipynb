{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "import os\n",
    "import random\n",
    "import scipy as sp\n",
    "import pickle\n",
    "\n",
    "import shutil\n",
    "import csv\n",
    "import ast\n",
    "import community as community_louvain\n",
    "\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from autoencoder import VariationalAutoEncoder\n",
    "from denoise_model import DenoiseNN, p_losses, sample\n",
    "from utils import linear_beta_schedule, construct_nx_from_adj, preprocess_dataset, graph_statistics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "np.random.seed(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(lr=0.001, dropout=0.1, batch_size=256, epochs_autoencoder=200, hidden_dim_encoder=64, hidden_dim_decoder=256, latent_dim=32, n_max_nodes=50, n_layers_encoder=2, n_layers_decoder=3, spectral_emb_dim=10, epochs_denoise=100, timesteps=500, hidden_dim_denoise=512, n_layers_denoise=3, train_autoencoder=False, train_denoiser=True, dim_condition=128, n_condition=7)\n"
     ]
    }
   ],
   "source": [
    "# Simulate command-line arguments\n",
    "sys.argv = [\n",
    "    'main.py',\n",
    "    '--lr', '0.001',\n",
    "    '--dropout', '0.1',\n",
    "    '--batch-size', '256',\n",
    "    '--epochs-autoencoder', '200',\n",
    "    '--hidden-dim-encoder', '64',\n",
    "    '--hidden-dim-decoder', '256',\n",
    "    '--latent-dim', '32',\n",
    "    '--n-max-nodes', '50',\n",
    "    '--n-layers-encoder', '2',\n",
    "    '--n-layers-decoder', '3',\n",
    "    '--spectral-emb-dim', '10',\n",
    "    '--epochs-denoise', '100',\n",
    "    '--timesteps', '500',\n",
    "    '--hidden-dim-denoise', '512',\n",
    "    '--n-layers_denoise', '3',\n",
    "    # '--train-autoencoder',\n",
    "    '--train-denoiser',\n",
    "    '--dim-condition', '128',\n",
    "    '--n-condition', '7'\n",
    "]\n",
    "\n",
    "# Initialize the parser\n",
    "parser = argparse.ArgumentParser(description=\"Your description here\")\n",
    "\n",
    "# Add arguments\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help=\"Learning rate for the optimizer, typically a small float value (default: 0.001)\")\n",
    "parser.add_argument('--dropout', type=float, default=0.0, help=\"Dropout rate (fraction of nodes to drop) to prevent overfitting (default: 0.0)\")\n",
    "parser.add_argument('--batch-size', type=int, default=256, help=\"Batch size for training, controlling the number of samples per gradient update (default: 256)\")\n",
    "parser.add_argument('--epochs-autoencoder', type=int, default=200, help=\"Number of training epochs for the autoencoder (default: 200)\")\n",
    "parser.add_argument('--hidden-dim-encoder', type=int, default=64, help=\"Hidden dimension size for encoder layers (default: 64)\")\n",
    "parser.add_argument('--hidden-dim-decoder', type=int, default=256, help=\"Hidden dimension size for decoder layers (default: 256)\")\n",
    "parser.add_argument('--latent-dim', type=int, default=32, help=\"Dimensionality of the latent space in the autoencoder (default: 32)\")\n",
    "parser.add_argument('--n-max-nodes', type=int, default=50, help=\"Possible maximum number of nodes in graphs (default: 50)\")\n",
    "parser.add_argument('--n-layers-encoder', type=int, default=2, help=\"Number of layers in the encoder network (default: 2)\")\n",
    "parser.add_argument('--n-layers-decoder', type=int, default=3, help=\"Number of layers in the decoder network (default: 3)\")\n",
    "parser.add_argument('--spectral-emb-dim', type=int, default=10, help=\"Dimensionality of spectral embeddings for representing graph structures (default: 10)\")\n",
    "parser.add_argument('--epochs-denoise', type=int, default=100, help=\"Number of training epochs for the denoising model (default: 100)\")\n",
    "parser.add_argument('--timesteps', type=int, default=500, help=\"Number of timesteps for the diffusion (default: 500)\")\n",
    "parser.add_argument('--hidden-dim-denoise', type=int, default=512, help=\"Hidden dimension size for denoising model layers (default: 512)\")\n",
    "parser.add_argument('--n-layers_denoise', type=int, default=3, help=\"Number of layers in the denoising model (default: 3)\")\n",
    "parser.add_argument('--train-autoencoder', action='store_true', default=False, help=\"Flag to enable/disable autoencoder (VGAE) training (default: enabled)\")\n",
    "parser.add_argument('--train-denoiser', action='store_true', default=False, help=\"Flag to enable/disable denoiser training (default: enabled)\")\n",
    "parser.add_argument('--dim-condition', type=int, default=128, help=\"Dimensionality of conditioning vectors for conditional generation (default: 128)\")\n",
    "parser.add_argument('--n-condition', type=int, default=7, help=\"Number of distinct condition properties used in conditional vector (default: 7)\")\n",
    "\n",
    "# Parse the arguments\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Use the arguments as needed\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flash Attention 2.0 only supports torch.float16 and torch.bfloat16 dtypes, but the current dype in ModernBertModel is torch.float32. You should run training or inference using Automatic Mixed-Precision via the `with torch.autocast(device_type='torch_device'):` decorator, or load the model with the `torch_dtype` argument. Example: `model = AutoModel.from_pretrained(\"openai/whisper-tiny\", attn_implementation=\"flash_attention_2\", torch_dtype=torch.float16)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[50281,   510,  5347,   273,  6181,   310, 50284,    15, 50282]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, ModernBertModel\n",
    "\n",
    "model_id = \"answerdotai/ModernBERT-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = ModernBertModel.from_pretrained(model_id)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "\n",
    "text = \"The capital of France is [MASK].\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "inputs.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "outputs = model(**inputs)\n",
    "print(outputs.last_hidden_state[:, 0, :].shape) #CLS token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2021/valentin.dorseuil/Desktop/altegrad_project/new_loss/utils.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  print(f'Dataset {filename} loaded from file')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ./data/dataset_train.pt loaded from file\n",
      "Dataset ./data/dataset_valid.pt loaded from file\n",
      "Dataset ./data/dataset_test.pt loaded from file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/eleves-b/2021/valentin.dorseuil/Desktop/altegrad_project/new_loss/utils.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_lst = torch.load(filename)\n"
     ]
    }
   ],
   "source": [
    "trainset = preprocess_dataset(\"train\", args.n_max_nodes, args.spectral_emb_dim)\n",
    "validset = preprocess_dataset(\"valid\", args.n_max_nodes, args.spectral_emb_dim)\n",
    "testset = preprocess_dataset(\"test\", args.n_max_nodes, args.spectral_emb_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(stats=[1, 7], filename='graph_0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.__getitem__(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
